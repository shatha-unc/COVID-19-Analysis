{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc0360c2-28e5-4f16-959d-a4e50f5c0de2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mild Classifier Results:\n",
      "Accuracy: 0.6345029239766082\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.66      0.65       177\n",
      "           1       0.62      0.61      0.62       165\n",
      "\n",
      "    accuracy                           0.63       342\n",
      "   macro avg       0.63      0.63      0.63       342\n",
      "weighted avg       0.63      0.63      0.63       342\n",
      "\n",
      "\n",
      "Severe Classifier Results:\n",
      "Accuracy: 0.7748538011695907\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.83      0.87       300\n",
      "           1       0.25      0.40      0.31        42\n",
      "\n",
      "    accuracy                           0.77       342\n",
      "   macro avg       0.58      0.62      0.59       342\n",
      "weighted avg       0.83      0.77      0.80       342\n",
      "\n",
      "Final Classifier Accuracy: 0.7125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82       135\n",
      "           1       0.26      0.44      0.32        25\n",
      "\n",
      "    accuracy                           0.71       160\n",
      "   macro avg       0.57      0.60      0.57       160\n",
      "weighted avg       0.78      0.71      0.74       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Step 1: Load COVID-19 data\n",
    "covid_data = pd.read_csv(\"data_covid.csv\")\n",
    "\n",
    "# Step 2: Preprocessing\n",
    "# Convert measurement_date to datetime\n",
    "covid_data['measurement_date'] = pd.to_datetime(covid_data['measurement_date'])\n",
    "\n",
    "# Keep only the measurements from the first day\n",
    "first_day_data = covid_data[covid_data['measurement_date'] == covid_data.groupby('person_id')['measurement_date'].transform('min')]\n",
    "\n",
    "# Pivot the data so that each measurement is a separate column\n",
    "first_day_pivot = first_day_data.pivot_table(index=['person_id', 'current_age', 'category', 'race_name', 'gen_name'], \n",
    "                                             columns='measurement_name', \n",
    "                                             values='value_as_number').reset_index()\n",
    "\n",
    "# Identify vital signs and lab measurements\n",
    "vital_signs = ['Diastolic blood pressure', 'Body temperature', 'Systolic blood pressure',\n",
    "               'Body weight', 'Respiratory rate', 'Oxygen saturation in Arterial blood']\n",
    "\n",
    "lab_measurements = ['Diastolic blood pressure', 'Body temperature', 'Respiratory rate',\n",
    "                    'Oxygen saturation in Arterial blood', 'Systolic blood pressure',\n",
    "                    'Body weight', 'Heart rate',\n",
    "                    'Hematocrit [Volume Fraction] of Blood by Automated count',\n",
    "                    'Erythrocytes [#/volume] in Blood by Automated count',\n",
    "                    'Aspartate aminotransferase [Enzymatic activity/volume] in Serum or Plasma',\n",
    "                    'Alanine aminotransferase [Enzymatic activity/volume] in Serum or Plasma',\n",
    "                    'Alkaline phosphatase [Enzymatic activity/volume] in Serum or Plasma',\n",
    "                    'Bilirubin.total [Mass/volume] in Serum or Plasma',\n",
    "                    'Albumin [Mass/volume] in Serum or Plasma',\n",
    "                    'MCHC [Mass/volume] by Automated count',\n",
    "                    'Hemoglobin [Mass/volume] in Blood',\n",
    "                    'Platelets [#/volume] in Blood by Automated count',\n",
    "                    'Glomerular filtration rate/1.73 sq M.predicted [Volume Rate/Area] in Serum, Plasma or Blood by Creatinine-based formula (MDRD)',\n",
    "                    'Protein [Mass/volume] in Serum or Plasma',\n",
    "                    'MCH [Entitic mass] by Automated count',\n",
    "                    'MCV [Entitic volume] by Automated count',\n",
    "                    'Leukocytes [#/volume] in Blood by Automated count'\n",
    "                   ]\n",
    "\n",
    "# Step 3: Preparing data for classification\n",
    "# Mild Classifier: Use only vital signs\n",
    "X_binary = first_day_pivot[vital_signs].values\n",
    "y_binary = (first_day_pivot['category'] != 'mild').astype(int).values\n",
    "\n",
    "# Severe Classifier: Use all features\n",
    "X_severe = first_day_pivot.drop(['person_id', 'current_age', 'category', 'race_name', 'gen_name'], axis=1).values\n",
    "y_severe = first_day_pivot['category'].apply(lambda x: 1 if x == 'severe' else 0).values\n",
    "\n",
    "# Step 4: Impute missing values with median\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_binary = imputer.fit_transform(X_binary)\n",
    "X_severe = imputer.fit_transform(X_severe)\n",
    "\n",
    "# Step 5: Splitting data into train and test sets\n",
    "X_train_binary, X_test_binary, y_train_binary, y_test_binary = train_test_split(X_binary, y_binary, test_size=0.2, random_state=42)\n",
    "X_train_severe, X_test_severe, y_train_severe, y_test_severe = train_test_split(X_severe, y_severe, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 6: Training classifiers\n",
    "# Binary Classifier: Decision Tree\n",
    "binary_classifier = DecisionTreeClassifier()\n",
    "binary_classifier.fit(X_train_binary, y_train_binary)\n",
    "\n",
    "# Severe Classifier: Decision Tree\n",
    "severe_classifier = DecisionTreeClassifier()\n",
    "severe_classifier.fit(X_train_severe, y_train_severe)\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Step 7: Combine predictions from mild and severe classifiers\n",
    "# Get predictions from mild classifier\n",
    "binary_predictions = binary_classifier.predict(X_test_binary)\n",
    "severe_predictions = severe_classifier.predict(X_test_severe)\n",
    "\n",
    "# Step 8: Evaluate classifiers\n",
    "# Mild Classifier evaluation\n",
    "print(\"Mild Classifier Results:\")\n",
    "binary_accuracy = accuracy_score(y_test_binary, binary_predictions)\n",
    "print(\"Accuracy:\", binary_accuracy)\n",
    "print(classification_report(y_test_binary, binary_predictions))\n",
    "\n",
    "# Severe Classifier evaluation\n",
    "print(\"\\nSevere Classifier Results:\")\n",
    "severe_accuracy = accuracy_score(y_test_severe, severe_predictions)\n",
    "print(\"Accuracy:\", severe_accuracy)\n",
    "print(classification_report(y_test_severe, severe_predictions))\n",
    "\n",
    "\n",
    "# Step 7: Combine predictions from mild and severe classifiers\n",
    "# Get predictions from mild classifier\n",
    "binary_predictions = binary_classifier.predict(X_test_binary)\n",
    "\n",
    "\n",
    "# Filter severe predictions based on mild predictions\n",
    "X_test_severe_final = X_test_severe[binary_predictions == 1]\n",
    "y_test_severe_final = y_test_severe[binary_predictions == 1]\n",
    "\n",
    "# Get predictions from severe classifier\n",
    "severe_predictions = severe_classifier.predict(X_test_severe_final)\n",
    "\n",
    "# Step 8: Evaluate final classifier\n",
    "final_accuracy = accuracy_score(y_test_severe_final, severe_predictions)\n",
    "print(\"Final Classifier Accuracy:\", final_accuracy)\n",
    "print(classification_report(y_test_severe_final, severe_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be4f4580-6be1-4898-97a1-924d6738e86c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mild Classifier Accuracy: 0.5409356725146199\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.78      0.64       177\n",
      "           1       0.55      0.28      0.37       165\n",
      "\n",
      "    accuracy                           0.54       342\n",
      "   macro avg       0.54      0.53      0.51       342\n",
      "weighted avg       0.54      0.54      0.51       342\n",
      "\n",
      "Severe Classifier Accuracy: 0.8801169590643275\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94       300\n",
      "           1       1.00      0.02      0.05        42\n",
      "\n",
      "    accuracy                           0.88       342\n",
      "   macro avg       0.94      0.51      0.49       342\n",
      "weighted avg       0.89      0.88      0.83       342\n",
      "\n",
      "Final Classifier Accuracy: 0.8372093023255814\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91        71\n",
      "           1       1.00      0.07      0.12        15\n",
      "\n",
      "    accuracy                           0.84        86\n",
      "   macro avg       0.92      0.53      0.52        86\n",
      "weighted avg       0.86      0.84      0.77        86\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Step 1: Load COVID-19 data\n",
    "covid_data = pd.read_csv(\"data_covid.csv\")\n",
    "\n",
    "# Step 2: Preprocessing\n",
    "# Convert measurement_date to datetime\n",
    "covid_data['measurement_date'] = pd.to_datetime(covid_data['measurement_date'])\n",
    "\n",
    "# Keep only the measurements from the first day\n",
    "first_day_data = covid_data[covid_data['measurement_date'] == covid_data.groupby('person_id')['measurement_date'].transform('min')]\n",
    "\n",
    "# Pivot the data so that each measurement is a separate column\n",
    "first_day_pivot = first_day_data.pivot_table(index=['person_id', 'current_age', 'category', 'race_name', 'gen_name'], \n",
    "                                             columns='measurement_name', \n",
    "                                             values='value_as_number').reset_index()\n",
    "\n",
    "# Identify vital signs and lab measurements\n",
    "vital_signs = ['Diastolic blood pressure', 'Body temperature', 'Systolic blood pressure',\n",
    "               'Body weight', 'Respiratory rate', 'Oxygen saturation in Arterial blood']\n",
    "\n",
    "lab_measurements = ['Diastolic blood pressure', 'Body temperature', 'Respiratory rate',\n",
    "                    'Oxygen saturation in Arterial blood', 'Systolic blood pressure',\n",
    "                    'Body weight', 'Heart rate',\n",
    "                    'Hematocrit [Volume Fraction] of Blood by Automated count',\n",
    "                    'Erythrocytes [#/volume] in Blood by Automated count',\n",
    "                    'Aspartate aminotransferase [Enzymatic activity/volume] in Serum or Plasma',\n",
    "                    'Alanine aminotransferase [Enzymatic activity/volume] in Serum or Plasma',\n",
    "                    'Alkaline phosphatase [Enzymatic activity/volume] in Serum or Plasma',\n",
    "                    'Bilirubin.total [Mass/volume] in Serum or Plasma',\n",
    "                    'Albumin [Mass/volume] in Serum or Plasma',\n",
    "                    'MCHC [Mass/volume] by Automated count',\n",
    "                    'Hemoglobin [Mass/volume] in Blood',\n",
    "                    'Platelets [#/volume] in Blood by Automated count',\n",
    "                    'Glomerular filtration rate/1.73 sq M.predicted [Volume Rate/Area] in Serum, Plasma or Blood by Creatinine-based formula (MDRD)',\n",
    "                    'Protein [Mass/volume] in Serum or Plasma',\n",
    "                    'MCH [Entitic mass] by Automated count',\n",
    "                    'MCV [Entitic volume] by Automated count',\n",
    "                    'Leukocytes [#/volume] in Blood by Automated count'\n",
    "                   ]\n",
    "\n",
    "# Step 3: Preparing data for classification\n",
    "# Mild Classifier: Use only vital signs\n",
    "X_binary = first_day_pivot[vital_signs].values\n",
    "y_binary = (first_day_pivot['category'] != 'mild').astype(int).values\n",
    "\n",
    "# Severe Classifier: Use all features\n",
    "X_severe = first_day_pivot.drop(['person_id', 'current_age', 'category', 'race_name', 'gen_name'], axis=1).values\n",
    "y_severe = first_day_pivot['category'].apply(lambda x: 1 if x == 'severe' else 0).values\n",
    "\n",
    "# Step 4: Impute missing values with median\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_binary = imputer.fit_transform(X_binary)\n",
    "X_severe = imputer.fit_transform(X_severe)\n",
    "\n",
    "# Step 5: Splitting data into train and test sets\n",
    "X_train_binary, X_test_binary, y_train_binary, y_test_binary = train_test_split(X_binary, y_binary, test_size=0.2, random_state=42)\n",
    "X_train_severe, X_test_severe, y_train_severe, y_test_severe = train_test_split(X_severe, y_severe, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 6: Training classifiers\n",
    "binary_classifier = LogisticRegression()\n",
    "binary_classifier.fit(X_train_binary, y_train_binary)\n",
    "\n",
    "# Severe Classifier: Logistic Regression\n",
    "severe_classifier = LogisticRegression()\n",
    "severe_classifier.fit(X_train_severe, y_train_severe)\n",
    "\n",
    "# Step 7: Evaluation\n",
    "# Mild Classifier evaluation\n",
    "binary_predictions = binary_classifier.predict(X_test_binary)\n",
    "binary_accuracy = accuracy_score(y_test_binary, binary_predictions)\n",
    "print(\"Mild Classifier Accuracy:\", binary_accuracy)\n",
    "print(classification_report(y_test_binary, binary_predictions))\n",
    "\n",
    "# Severe Classifier evaluation\n",
    "severe_predictions = severe_classifier.predict(X_test_severe)\n",
    "severe_accuracy = accuracy_score(y_test_severe, severe_predictions)\n",
    "\n",
    "print(\"Severe Classifier Accuracy:\", severe_accuracy)\n",
    "print(classification_report(y_test_severe, severe_predictions))\n",
    "\n",
    "# Step 8: Combine predictions from binary and severe classifiers\n",
    "# Get predictions from mild classifier\n",
    "binary_predictions = binary_classifier.predict(X_test_binary)\n",
    "\n",
    "# Filter severe predictions based on mild predictions\n",
    "X_test_severe_final = X_test_severe[binary_predictions == 1]\n",
    "y_test_severe_final = y_test_severe[binary_predictions == 1]\n",
    "\n",
    "# Get predictions from severe classifier\n",
    "severe_predictions = severe_classifier.predict(X_test_severe_final)\n",
    "\n",
    "\n",
    "# Step 7: Combine predictions from mild and severe classifiers\n",
    "# Get predictions from mild classifier\n",
    "binary_predictions = binary_classifier.predict(X_test_binary)\n",
    "\n",
    "# Filter severe predictions based on mild predictions\n",
    "X_test_severe_final = X_test_severe[binary_predictions == 1]\n",
    "y_test_severe_final = y_test_severe[binary_predictions == 1]\n",
    "\n",
    "# Get predictions from severe classifier\n",
    "severe_predictions = severe_classifier.predict(X_test_severe_final)\n",
    "\n",
    "# Step 8: Evaluate final classifier\n",
    "final_accuracy = accuracy_score(y_test_severe_final, severe_predictions)\n",
    "print(\"Final Classifier Accuracy:\", final_accuracy)\n",
    "print(classification_report(y_test_severe_final, severe_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d285a08f-5069-499c-a426-1b9b339cf57d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 1: Demographic Characteristics of Patient Population\n",
      "\tMild COVID\t\tModerate COVID\t\tSevere COVID\n",
      "Sex\n",
      "gen_name  FEMALE  MALE  Total\n",
      "category                     \n",
      "mild         519   463    982\n",
      "moderate     279   235    514\n",
      "severe        91   123    214\n",
      "\n",
      "Age\n",
      "Age_Group  < 18  18 - 45  46 - 65  > 65  Total\n",
      "category                                      \n",
      "mild        220      361      235   166    982\n",
      "moderate     24      140      187   163    514\n",
      "severe        2       22       64   126    214\n",
      "\n",
      "Race\n",
      "race_name  Asian  Black or African American  No matching concept  White  Total\n",
      "category                                                                      \n",
      "mild          63                         69                    8    842    982\n",
      "moderate      41                         43                    3    427    514\n",
      "severe        13                         20                    0    181    214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3703753/3650730498.py:9: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouped_age = first_day_pivot.groupby(['category', 'Age_Group']).size().unstack(fill_value=0)\n"
     ]
    }
   ],
   "source": [
    "# Group by COVID Severity and Sex\n",
    "grouped_sex = first_day_pivot.groupby(['category', 'gen_name']).size().unstack(fill_value=0)\n",
    "grouped_sex['Total'] = grouped_sex.sum(axis=1)\n",
    "\n",
    "# Group by COVID Severity and Age Group\n",
    "age_bins = [0, 18, 45, 65, 150]  # Define age bins\n",
    "age_labels = ['< 18', '18 - 45', '46 - 65', '> 65']  # Define age group labels\n",
    "first_day_pivot['Age_Group'] = pd.cut(first_day_pivot['current_age'], bins=age_bins, labels=age_labels)\n",
    "grouped_age = first_day_pivot.groupby(['category', 'Age_Group']).size().unstack(fill_value=0)\n",
    "grouped_age['Total'] = grouped_age.sum(axis=1)\n",
    "\n",
    "# Group by COVID Severity and Race\n",
    "grouped_race = first_day_pivot.groupby(['category', 'race_name']).size().unstack(fill_value=0)\n",
    "grouped_race['Total'] = grouped_race.sum(axis=1)\n",
    "\n",
    "# Print table\n",
    "print(\"Table 1: Demographic Characteristics of Patient Population\")\n",
    "print(\"\\tMild COVID\\t\\tModerate COVID\\t\\tSevere COVID\")\n",
    "print(\"Sex\")\n",
    "print(grouped_sex)\n",
    "\n",
    "print(\"\\nAge\")\n",
    "print(grouped_age)\n",
    "\n",
    "print(\"\\nRace\")\n",
    "print(grouped_race)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709c2693",
   "metadata": {},
   "source": [
    "End of Notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
