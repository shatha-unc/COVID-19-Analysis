{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dd87d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# COVID-19 Severity Classification and Demographic Analysis\\n\",\n",
    "    \"\\n\",\n",
    "    \"This project analyzes patient measurement data to classify **COVID-19 severity** and explore **demographic trends** (age, race, gender).\\n\",\n",
    "    \"\\n\",\n",
    "    \"It demonstrates data preprocessing, feature engineering, imputation, classification modeling, and exploratory demographic grouping using **Python**, **pandas**, and **scikit-learn**.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Step 1: Import Libraries\\n\",\n",
    "    \"We use pandas for data handling and scikit-learn for preprocessing and classification.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"from sklearn.model_selection import train_test_split\\n\",\n",
    "    \"from sklearn.impute import SimpleImputer\\n\",\n",
    "    \"from sklearn.linear_model import LogisticRegression\\n\",\n",
    "    \"from sklearn.metrics import accuracy_score, classification_report\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Step 2: Load and Preprocess the Data\\n\",\n",
    "    \"We load the dataset, convert date fields, and retain only the **first measurement** per patient.  \\n\",\n",
    "    \"Next, we pivot the dataset so that each measurement type becomes a column.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Load dataset\\n\",\n",
    "    \"covid_data = pd.read_csv(\\\"data_covid.csv\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Convert measurement_date to datetime\\n\",\n",
    "    \"covid_data['measurement_date'] = pd.to_datetime(covid_data['measurement_date'])\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Keep only first measurement per person\\n\",\n",
    "    \"first_day_data = covid_data[\\n\",\n",
    "    \"    covid_data['measurement_date'] == covid_data.groupby('person_id')['measurement_date'].transform('min')\\n\",\n",
    "    \"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Pivot: measurement types as columns\\n\",\n",
    "    \"first_day_pivot = first_day_data.pivot_table(\\n\",\n",
    "    \"    index=['person_id', 'current_age', 'category', 'race_name', 'gen_name'],\\n\",\n",
    "    \"    columns='measurement_name',\\n\",\n",
    "    \"    values='value_as_number'\\n\",\n",
    "    \").reset_index()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Step 3: Define Feature Groups\\n\",\n",
    "    \"We use:\\n\",\n",
    "    \"- **Vital Signs** for the mild vs. non-mild classification.\\n\",\n",
    "    \"- **All Lab Measurements** for the severe classifier.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"vital_signs = [\\n\",\n",
    "    \"    'Diastolic blood pressure', 'Body temperature', 'Systolic blood pressure',\\n\",\n",
    "    \"    'Body weight', 'Respiratory rate', 'Oxygen saturation in Arterial blood'\\n\",\n",
    "    \"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"lab_measurements = [\\n\",\n",
    "    \"    'Heart rate', 'Hematocrit [Volume Fraction] of Blood by Automated count',\\n\",\n",
    "    \"    'Erythrocytes [#/volume] in Blood by Automated count',\\n\",\n",
    "    \"    'Aspartate aminotransferase [Enzymatic activity/volume] in Serum or Plasma',\\n\",\n",
    "    \"    'Alanine aminotransferase [Enzymatic activity/volume] in Serum or Plasma',\\n\",\n",
    "    \"    'Alkaline phosphatase [Enzymatic activity/volume] in Serum or Plasma',\\n\",\n",
    "    \"    'Bilirubin.total [Mass/volume] in Serum or Plasma',\\n\",\n",
    "    \"    'Albumin [Mass/volume] in Serum or Plasma', 'MCHC [Mass/volume] by Automated count',\\n\",\n",
    "    \"    'Hemoglobin [Mass/volume] in Blood', 'Platelets [#/volume] in Blood by Automated count',\\n\",\n",
    "    \"    'Glomerular filtration rate/1.73 sq M.predicted [Volume Rate/Area] in Serum, Plasma or Blood by Creatinine-based formula (MDRD)',\\n\",\n",
    "    \"    'Protein [Mass/volume] in Serum or Plasma', 'MCH [Entitic mass] by Automated count',\\n\",\n",
    "    \"    'MCV [Entitic volume] by Automated count', 'Leukocytes [#/volume] in Blood by Automated count'\\n\",\n",
    "    \"] + vital_signs\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Step 4: Prepare Data for Classification\\n\",\n",
    "    \"- **Binary Classifier:** distinguishes *mild* vs. *non-mild* cases (using only vital signs).  \\n\",\n",
    "    \"- **Severe Classifier:** predicts *severe* vs. *non-severe* cases (using all lab measurements).\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Mild vs Non-Mild\\n\",\n",
    "    \"X_binary = first_day_pivot[vital_signs].values\\n\",\n",
    "    \"y_binary = (first_day_pivot['category'] != 'mild').astype(int).values\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Severe vs Non-Severe\\n\",\n",
    "    \"X_severe = first_day_pivot[lab_measurements].values\\n\",\n",
    "    \"y_severe = first_day_pivot['category'].apply(lambda x: 1 if x == 'severe' else 0).values\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Handle missing values\\n\",\n",
    "    \"imputer = SimpleImputer(strategy='median')\\n\",\n",
    "    \"X_binary = imputer.fit_transform(X_binary)\\n\",\n",
    "    \"X_severe = imputer.fit_transform(X_severe)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"##  Step 5: Split Data into Training and Test Sets\\n\",\n",
    "    \"We reserve 20% of the data for evaluation.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"X_train_binary, X_test_binary, y_train_binary, y_test_binary = train_test_split(\\n\",\n",
    "    \"    X_binary, y_binary, test_size=0.2, random_state=42\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"X_train_severe, X_test_severe, y_train_severe, y_test_severe = train_test_split(\\n\",\n",
    "    \"    X_severe, y_severe, test_size=0.2, random_state=42\\n\",\n",
    "    \")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"##  Step 6: Train Logistic Regression Models\\n\",\n",
    "    \"We use Logistic Regression for interpretability and baseline classification.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"binary_classifier = LogisticRegression(max_iter=1000)\\n\",\n",
    "    \"severe_classifier = LogisticRegression(max_iter=1000)\\n\",\n",
    "    \"\\n\",\n",
    "    \"binary_classifier.fit(X_train_binary, y_train_binary)\\n\",\n",
    "    \"severe_classifier.fit(X_train_severe, y_train_severe)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"##  Step 7: Evaluate Models\\n\",\n",
    "    \"We assess model accuracy and classification performance using precision, recall, and F1-score.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Mild vs Non-Mild\\n\",\n",
    "    \"binary_preds = binary_classifier.predict(X_test_binary)\\n\",\n",
    "    \"print(\\\"Mild Classifier Results:\\\")\\n\",\n",
    "    \"print(\\\"Accuracy:\\\", accuracy_score(y_test_binary, binary_preds))\\n\",\n",
    "    \"print(classification_report(y_test_binary, binary_preds))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Severe vs Non-Severe\\n\",\n",
    "    \"severe_preds = severe_classifier.predict(X_test_severe)\\n\",\n",
    "    \"print(\\\"\\\\n Severe Classifier Results:\\\")\\n\",\n",
    "    \"print(\\\"Accuracy:\\\", accuracy_score(y_test_severe, severe_preds))\\n\",\n",
    "    \"print(classification_report(y_test_severe, severe_preds))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Step 8: Cascaded Prediction (Two-Stage Classification)\\n\",\n",
    "    \"We first predict *non-mild* cases, then use the **severe classifier** only on those patients.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Filter test set for severe classification only if non-mild\\n\",\n",
    "    \"binary_predictions = binary_classifier.predict(X_test_binary)\\n\",\n",
    "    \"X_test_severe_final = X_test_severe[binary_predictions == 1]\\n\",\n",
    "    \"y_test_severe_final = y_test_severe[binary_predictions == 1]\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Predict severe cases\\n\",\n",
    "    \"final_preds = severe_classifier.predict(X_test_severe_final)\\n\",\n",
    "    \"print(\\\"\\\\n Final Cascaded Classifier Results:\\\")\\n\",\n",
    "    \"print(\\\"Accuracy:\\\", accuracy_score(y_test_severe_final, final_preds))\\n\",\n",
    "    \"print(classification_report(y_test_severe_final, final_preds))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Step 9: Demographic Analysis\\n\",\n",
    "    \"We analyze COVID severity distribution by **sex**, **age group**, and **race**.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Group by Sex\\n\",\n",
    "    \"grouped_sex = first_day_pivot.groupby(['category', 'gen_name']).size().unstack(fill_value=0)\\n\",\n",
    "    \"grouped_sex['Total'] = grouped_sex.sum(axis=1)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Group by Age\\n\",\n",
    "    \"age_bins = [0, 18, 45, 65, 150]\\n\",\n",
    "    \"age_labels = ['< 18', '18 - 45', '46 - 65', '> 65']\\n\",\n",
    "    \"first_day_pivot['Age_Group'] = pd.cut(first_day_pivot['current_age'], bins=age_bins, labels=age_labels)\\n\",\n",
    "    \"grouped_age = first_day_pivot.groupby(['category', 'Age_Group']).size().unstack(fill_value=0)\\n\",\n",
    "    \"grouped_age['Total'] = grouped_age.sum(axis=1)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Group by Race\\n\",\n",
    "    \"grouped_race = first_day_pivot.groupby(['category', 'race_name']).size().unstack(fill_value=0)\\n\",\n",
    "    \"grouped_race['Total'] = grouped_race.sum(axis=1)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Display demographic tables\\n\",\n",
    "    \"print(\\\"\\\\n Table 1: Demographic Characteristics of Patient Population\\\\n\\\")\\n\",\n",
    "    \"print(\\\"By Sex:\\\\n\\\", grouped_sex)\\n\",\n",
    "    \"print(\\\"\\\\nBy Age Group:\\\\n\\\", grouped_age)\\n\",\n",
    "    \"print(\\\"\\\\nBy Race:\\\\n\\\", grouped_race)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Summary\\n\",\n",
    "    \"This analysis:\\n\",\n",
    "    \"- Preprocessed COVID-19 measurement data into a structured, per-patient format  \\n\",\n",
    "    \"- Built and evaluated a two-stage **mild/non-mild → severe** classification pipeline  \\n\",\n",
    "    \"- Explored demographic patterns by sex, age, and race  \\n\",\n",
    "    \"\\n\",\n",
    "    \"**Future Work:**\\n\",\n",
    "    \"- Try Random Forest or XGBoost for better accuracy  \\n\",\n",
    "    \"- Apply SMOTE to handle class imbalance  \\n\",\n",
    "    \"- Add feature importance and interpretability (e.g., SHAP)\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"name\": \"python\",\n",
    "   \"version\": \"3.11\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
